+ 写在开始
微积分的起源是逼近法，逼近法最初是为了求曲线面积搞出来的。
在深度模型中，我们训练模型期待他在越来越多数据的时候变得越来越好。一般情况我们只关注损失函数，即最小化损失函数。
深度学习我们将模型任务分解为两个关键问题：
1、优化（optimization）：用模型拟合观测数据
2、泛化（generalization）：数学原理和实践者的智慧，能指导我们生成有效性超出训练数据本身的模型

# 2.4.1 导数和微分
定义一个函数$$u=f(x)=3x^2-4x$$
```python
import numpy as np
from matplotlib_inline import backend_inline
from d2l import tensorflow as d2l
def f(x):
    return 3 * x ** 2 - 4 * x
```
通过令x=1并让 h 金额近于0$\frac{f(x+h)-f(x)}{h}$的数值结果接近2.
```python 
def numerical_lim(f, x, h):
    return (f(x+h)-f(x)) / h
h = 0.1
for i in range(5):
    print(f'h={h:.5f},numerical limit={numerical_lim(f, 1, h):.5f}')
    h *= 0.1
```


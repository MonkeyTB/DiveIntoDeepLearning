+ 写在前面
机器学习的目标是发现模式，我们如何确定模型是真的发现了模式，而不是简单的记住数据呢？

## 4.4.1 训练误差和泛化误差
训练误差：模型在训练数据集上得到的误差
泛化误差：模型在同样分布的数据上的误差的期望

###  4.4.1.3 模型复杂性
当我们有简单的模型和大量的数据时，我们期望泛化误差与训练误差相近。 当我们有更复杂的模型和更少的样本时，我们预计训练误差会下降，但泛化误差会增大。 模型复杂性由什么构成是一个复杂的问题。 一个模型是否能很好地泛化取决于很多因素。 例如，具有更多参数的模型可能被认为更复杂， 参数有更大取值范围的模型可能更为复杂。 通常对于神经网络，我们认为需要更多训练迭代的模型比较复杂， 而需要早停（early stopping）的模型（即较少训练迭代周期）就不那么复杂。

本节为了给出一些直观的印象，我们将重点介绍几个倾向于影响模型泛化的因素。
1、可调整参数的数量。当可调整参数的数量（有时称为自由度）很大时，模型往往更容易过拟合。
2、参数采用的值。当权重的取值范围较大时，模型可能更容易过拟合。
3、训练样本的数量。即使模型很简单，也很容易过拟合只包含一两个样本的数据集。而过拟合一个有数百万个样本的数据集则需要一个极其灵活的模型。